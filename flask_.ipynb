{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d29f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install anvil-uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402014b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:54:34.847125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/chriskinyash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/chriskinyash/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/chriskinyash/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import unidecode\n",
    "import contractions\n",
    "import re\n",
    "from word2number import w2n\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23bdc23a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TFBertModel,BertConfig, BertTokenizerFast\n",
    "from transformers import AlbertConfig, AlbertTokenizerFast, TFAlbertModel\n",
    "import os\n",
    "import numpy as np \n",
    "import uuid\n",
    "import anvil.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0861fc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertMainLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super(TFBertMainLayer, self).__init__(**kwargs)\n",
    "        self.bert = TFBertModel.from_pretrained('bert-base-uncased', config=config)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.bert(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ecd85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "    text = input_text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=100,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='tf',\n",
    "    verbose = True)\n",
    "    return {\n",
    "     'input_ids':tf.cast(token.input_ids, tf.float64),\n",
    "     'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59568cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\" A function to preprocess text\"\"\"\n",
    "    #convert Non-ASCII characters to ASCII\n",
    "    text = unidecode.unidecode(text)\n",
    "    \n",
    "    # Expand shortened words, e.g. don't to do not\"\"\"\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # removes special characters from text, e.g. $\"\"\"\n",
    "    clean = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "    text = re.sub(clean, ' ', text)\n",
    "    # converts characters to lowercase\"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove patterns\n",
    "    text = re.sub(r'xxxx', r'', text)\n",
    "    \n",
    "    # Convert number words to digits and remove them\"\"\"\n",
    "    \n",
    "    pattern = r'(\\W+)'\n",
    "    tokens = re.split(pattern, text)\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        try:\n",
    "            tokens[i] = str(w2n.word_to_num(token))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    text = ''.join(tokens)\n",
    "\n",
    "    # removes numbers from text\"\"\"\n",
    "    clean_1 = re.compile(r'\\d+')\n",
    "    \n",
    "    text = re.sub(clean_1, '', text)\n",
    "\n",
    "    # removes words with length 1 or 2\"\"\"\n",
    "    clean = re.compile(r'\\b\\w{1,2}\\b')\n",
    "    \n",
    "    text = re.sub(clean, '', text)\n",
    "    \n",
    "    # removes the stopwords in the text\"\"\"\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stopwords = set(stopwords)\n",
    "    \n",
    "    tokens = re.split(r'(\\W+)', text)\n",
    "    \n",
    "    text = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "    text = ' '.join(text)\n",
    "\n",
    "    # Remove extra spaces from a string\"\"\"\n",
    "    \n",
    "    clean = re.compile(r'\\s{2,10000}')\n",
    "    text = re.sub(clean, ' ', text)\n",
    "\n",
    "\n",
    "    lemma = WordNetLemmatizer()\n",
    "    \n",
    "    tokens = re.split('\\W+', text)\n",
    "    \n",
    "    text = [lemma.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a144d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define out classes for ease of modelling \n",
    "class Warehouse_Model(object):\n",
    "    \"\"\"Class to save your model architecture and Model Weights correctly\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "   \n",
    "    def save(model,file_path):\n",
    "        \"\"\"\n",
    "        Function for saving both the model and weights to your file_path\n",
    "        Follow this structure ['/file_path/name_you_want_to_save_as']\n",
    "        \"\"\"\n",
    "        SaveModel = tf.saved_model.save(model, file_path)\n",
    "        \n",
    "        \n",
    "        SaveWeights = model.save_weights(file_path + '.h5')\n",
    "        \n",
    "        return print(f'Model and Weights saved SUCCESSFULLY in:{file_path}')\n",
    "    \n",
    "    def load(file_path):\n",
    "        \n",
    "        \"\"\"Follow this structure ['/file_path/name_of_file containing your model!']\"\"\"\n",
    "        # Load The Model\n",
    "        LoadModel = tf.keras.models.load_model(\"model_path\")\n",
    "        \n",
    "        return LoadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a79f90-b44e-4f5d-a57f-b4f017ab49dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:54:37.743206: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-16 14:54:37.743320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-16 14:54:37.770172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:37.770318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX TITAN X computeCapability: 5.2\n",
      "coreClock: 1.2155GHz coreCount: 24 deviceMemorySize: 11.92GiB deviceMemoryBandwidth: 313.37GiB/s\n",
      "2023-01-16 14:54:37.770328: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-16 14:54:37.771067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-16 14:54:37.771092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-16 14:54:37.771983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-16 14:54:37.772119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-16 14:54:37.772797: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-16 14:54:37.773106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-16 14:54:37.774482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-16 14:54:37.774570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:37.774723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:37.774827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-16 14:54:37.775077: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-16 14:54:37.775765: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-16 14:54:37.775826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:37.775940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX TITAN X computeCapability: 5.2\n",
      "coreClock: 1.2155GHz coreCount: 24 deviceMemorySize: 11.92GiB deviceMemoryBandwidth: 313.37GiB/s\n",
      "2023-01-16 14:54:37.775949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-16 14:54:37.775961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-16 14:54:37.775970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-16 14:54:37.775978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-16 14:54:37.775986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-16 14:54:37.775994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-16 14:54:37.776002: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-16 14:54:37.776009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-16 14:54:37.776048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:37.776187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:37.776287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-16 14:54:37.776303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-16 14:54:38.016272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-16 14:54:38.016298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-01-16 14:54:38.016302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-01-16 14:54:38.016550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:38.016711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:38.016851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-16 14:54:38.016960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10741 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX TITAN X, pci bus id: 0000:09:00.0, compute capability: 5.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function TFAlbertMainLayer.call at 0x7f7a97788160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpfwgpr0eb.py, line 115)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function TFAlbertMainLayer.call at 0x7f7a97788160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpfwgpr0eb.py, line 115)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "Best_Model = tf.keras.models.load_model('ALBERT_SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6be430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Class for loading transformers from Hugging face.\n",
    "class LoadBert(object):\n",
    "    \n",
    "    \"\"\"A class that loads a bert model, tokenizer and a transformer\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def loadModel(modelName):\n",
    "        \"\"\"Loading the model name\"\"\"\n",
    "        model = modelName\n",
    "        return model\n",
    "\n",
    "    def config (Bert_Configuration, modelName, outputhidden_states:bool):\n",
    "        \"\"\"Model configuration\"\"\"\n",
    "        config = Bert_Configuration.from_pretrained(modelName)\n",
    "        config.outputhidden_states = False\n",
    "        return config\n",
    "\n",
    "    def tokenizer(tokenizer, modelName, config):\n",
    "        \"\"\"Text tokenizer\"\"\"\n",
    "        tokenizer = tokenizer.from_pretrained(pretrained_model_name_or_path = modelName, config =config)\n",
    "        return tokenizer\n",
    "\n",
    "    def transformerModel(BertClass, modelName, config):\n",
    "        \"\"\"Hugging face transformer model\"\"\"\n",
    "        transformerModel = BertClass.from_pretrained(modelName, config)\n",
    "        return transformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d98b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:54:46.247527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "Some layers from the model checkpoint at albert-base-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-base-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Loading ALbert\n",
    "ALBERT_v2 = LoadBert\n",
    "\n",
    "# Tokenizer\n",
    "tokenize_BERT = ALBERT_v2.tokenizer(tokenizer=AlbertTokenizerFast,\n",
    "                                    config=AlbertConfig,\n",
    "                                    modelName='albert-base-v2')\n",
    "\n",
    "# Transformer Model\n",
    "albert_model = ALBERT_v2.transformerModel(BertClass=TFAlbertModel, \n",
    "                                          config=AlbertConfig,\n",
    "                                          modelName='albert-base-v2')\n",
    "\n",
    "# Model configuration\n",
    "config_ALBERT = ALBERT_v2.config(AlbertConfig, \n",
    "                                 modelName='albert-base-v2', \n",
    "                                 outputhidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e40abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timely_response_dict ={\n",
    " 0: 'No',\n",
    " 1: 'Yes'}\n",
    "\n",
    "product_dict ={\n",
    " 0: 'Bank account or service',\n",
    " 1: 'Consumer Loan',\n",
    " 2: 'Credit card',\n",
    " 3: 'Credit reporting',\n",
    " 4: 'Debt collection',\n",
    " 5: 'Money transfers',\n",
    " 6: 'Mortgage',\n",
    " 7: 'Other financial service',\n",
    " 8: 'Payday loan',\n",
    " 9: 'Prepaid card',\n",
    " 10: 'Student loan',\n",
    " 11: 'Virtual currency'}\n",
    "\n",
    "disputed_dict ={\n",
    " 0: 'No', 1: 'Yes'}\n",
    "\n",
    "company_response_dict = {\n",
    " 0: 'Closed',\n",
    " 1: 'Closed with explanation',\n",
    " 2: 'Closed with monetary relief',\n",
    " 3: 'Closed with non-monetary relief',\n",
    " 4: 'Untimely response'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a97931-6fe0-4805-8a15-2a849ee0d67b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "anvil.server.connect(\"YQHV3BXLTQKWBYWUAA62TNML-RH7IVEVSJV6MZMCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2f456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 14:55:27.984870: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-01-16 14:55:28.004892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3693190000 Hz\n",
      "/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:592: UserWarning: Input dict contained keys ['attention_mask'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/site-packages/anvil/server.py\", line 405, in call\n",
      "    return _do_call(args, kwargs, fn_name=fn_name)\n",
      "  File \"/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/site-packages/anvil/server.py\", line 395, in _do_call\n",
      "    return _threaded_server.do_call(args, kwargs, fn_name=fn_name, live_object=live_object)\n",
      "  File \"/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/site-packages/anvil/_threaded_server.py\", line 435, in do_call\n",
      "    raise error_from_server\n",
      "anvil._server.AnvilWrappedError: 'Connection to Anvil Uplink server lost'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/site-packages/anvil/server.py\", line 206, in heartbeat_until_reopened\n",
      "    call(\"anvil.private.echo\", \"keep-alive\")\n",
      "  File \"/home/chriskinyash/anaconda3/envs/TF/lib/python3.9/site-packages/anvil/server.py\", line 408, in call\n",
      "    raise _server._deserialise_exception(e.error_obj)\n",
      "anvil._server.AnvilWrappedError: 'Connection to Anvil Uplink server lost'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anvil websocket closed (code 1006, reason=Going away)\n",
      "Reconnecting Anvil Uplink...\n",
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@anvil.server.callable\n",
    "\n",
    "\n",
    "def predict(input_text):\n",
    "\n",
    "    # Preprocess the text\n",
    "    clean_text = preprocess_text(input_text)\n",
    "    # Tokenize the input text\n",
    "    tokenized_text_input = prepare_data(input_text=clean_text, tokenizer=tokenize_BERT)\n",
    "    \n",
    "    # Create the prediction dictionary to return\n",
    "    prediction = {\n",
    "        \"timely_response\": None,\n",
    "        \"product\": None,\n",
    "        \"company_response\": None,\n",
    "        \"disputed\": None\n",
    "    }\n",
    "       # Use the model to make a prediction\n",
    "    preds = Best_Model.predict(tokenized_text_input)\n",
    "    \n",
    "\n",
    "    timely_response_prediction = np.argmax(preds['timely_response'])\n",
    "    product_prediction = np.argmax(preds['product'])\n",
    "    company_response_prediction = np.argmax(preds['company_response'])\n",
    "    disputed_prediction = np.argmax(preds['disputed'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction[\"timely_response\"] = timely_response_dict[int(timely_response_prediction)]\n",
    "    prediction[\"product\"] = product_dict[int(product_prediction)]\n",
    "    prediction[\"company_response\"] = company_response_dict[int(company_response_prediction)]\n",
    "    prediction[\"disputed\"] = disputed_dict[int(disputed_prediction)]\n",
    "\n",
    "# Return the prediction as a JSON response\n",
    "    return prediction\n",
    "\n",
    "anvil.server.wait_forever()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8dce912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = ' made balance transfer onto chase credit card interest rate total subsequently making minimum payment well additional payment cover purchase recently found payment applied pursuant credit card bill right minimum payment applied lower rate payment minimum also applied lower rate instead higher rate required balance instead balance higher rate payment misapplied '\n",
    "# Preprocess the text\n",
    "clean_text = preprocess_text(text)\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize the input text\n",
    "tokenized_text_input = prepare_data(input_text=clean_text, tokenizer=tokenizer)\n",
    "preds = Best_Model.predict(tokenized_text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a1b6833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': array([[0.5540818 , 0.47563013, 0.60292786, 0.81291145, 0.854082  ,\n",
       "         0.34129182, 0.6212632 , 0.27046806, 0.3122816 , 0.29392916,\n",
       "         0.47677657, 0.27023846]], dtype=float32),\n",
       " 'company_response': array([[0.25550836, 0.8570209 , 0.3731316 , 0.59634316, 0.28639954]],\n",
       "       dtype=float32),\n",
       " 'disputed': array([[0.5518131 , 0.22720681]], dtype=float32),\n",
       " 'timely_response': array([[0.1686151, 0.7738379]], dtype=float32)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73a7c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction = {\n",
    "        \"timely_response\": None,\n",
    "        \"product\": None,\n",
    "        \"company_response\": None,\n",
    "        \"disputed\": None\n",
    "    }\n",
    "timely_response_prediction = np.argmax(preds['timely_response'])\n",
    "product_prediction = np.argmax(preds['product'])\n",
    "company_response_prediction = np.argmax(preds['company_response'])\n",
    "disputed_prediction = np.argmax(preds['disputed'])\n",
    "    \n",
    "    \n",
    "    \n",
    "prediction[\"timely_response\"] = timely_response_dict[int(timely_response_prediction)]\n",
    "prediction[\"product\"] = product_dict[int(product_prediction)]\n",
    "prediction[\"company_response\"] = company_response_dict[int(company_response_prediction)]\n",
    "prediction[\"disputed\"] = disputed_dict[int(disputed_prediction)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc1ced88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timely_response': 'Yes',\n",
       " 'product': 'Debt collection',\n",
       " 'company_response': 'Closed with explanation',\n",
       " 'disputed': 'No'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea1b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a647ec254089a7e33080c556061baac188fc900ad5706e80c2a922c85fa24c2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
